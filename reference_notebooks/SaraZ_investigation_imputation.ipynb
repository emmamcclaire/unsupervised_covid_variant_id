{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sonic-liver",
   "metadata": {},
   "source": [
    "# Raise your hand if you are not here:\n",
    "<img src=\"raisehand2.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-franklin",
   "metadata": {},
   "source": [
    "### What we have for this investigation:\n",
    "- a couple concepts...\n",
    "- a couple graphs to visualize missing data...\n",
    "- three simple imputation examples...\n",
    "- testing the imputed datasets...\n",
    "- categorical feature..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-resistance",
   "metadata": {},
   "source": [
    "### Assume you have invistigated into the reasons why values are missing and have decided what to do...\n",
    "### Univariate vs Multivariate imputation\n",
    "From lecture, we learned two missing value handling strategies \n",
    "1. dropping rows with missing values \n",
    "2. fill missing values with mean, median, etc <br>\n",
    "Strategy 2 is what we call a univariate imputation where you use the observed values from the feature to fill in the missing values. <br>\n",
    "**BUT... we could also use the entire set of features in the dataset to estimate the missing values in a feature!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-essay",
   "metadata": {},
   "source": [
    "### How does multivariate imputation work?\n",
    "For a feature with missing values, its observed values (as the output) is regressed on the other features (as the input) in the data, and then the regressor is used to predict the missing values. This is done for each feature with missing values in an iterative fashion. The results of the final round of imputation are returned. <br>\n",
    "1. Missing values are filled in randomly from observed values\n",
    "2. Apply regressor to impute feature one at a time\n",
    "3. Terminate iteration when the average imputed values converge\n",
    "\n",
    "<img src=\"mice_flow_chart.png\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-developer",
   "metadata": {},
   "source": [
    "### Also just so you know, there are Single vs. Multiple Imputations:\n",
    "- If we were interested in understanding the uncertainty associated with the missing values, the dataset should be imputed multiple times and each set is used for separate analysis. \n",
    "> Imputing one value for a missing datum cannot be correct in general, because we don’t know what value to impute with certainty (if we did, it wouldn’t be missing). -- **Donald B. Rubin**\n",
    "- IterativeImputer only returns the result of a single imputation (because for preditive modeling, uncertainty is less of an interest). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tired-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-teddy",
   "metadata": {},
   "source": [
    "### Loading the iris dataset from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "contrary-investment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "species              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris() \n",
    "df = pd.DataFrame(data = np.c_[iris[\"data\"], iris[\"target\"]],\\\n",
    "                     columns = iris[\"feature_names\"] + [\"species\"])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "honey-length",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-questionnaire",
   "metadata": {},
   "source": [
    "### Introducing missing values in sepal_length and petal_width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weighted-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    15\n",
       "sepal width (cm)      0\n",
       "petal length (cm)     0\n",
       "petal width (cm)     10\n",
       "species               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss = df.copy()\n",
    "\n",
    "np.random.seed(11)\n",
    "mask = np.random.randint(0, 150, size = 15)\n",
    "mask2 = np.random.randint(0, 150, size = 10)\n",
    "\n",
    "df_miss[\"sepal length (cm)\"][mask] = np.nan\n",
    "df_miss[\"petal width (cm)\"][mask2] = np.nan\n",
    "df_miss.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-authorization",
   "metadata": {},
   "source": [
    "### Visualizing missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is also msno.bar(df)\n",
    "msno.matrix(df_miss, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows the correlation between missing values of the two features\n",
    "msno.heatmap(df_miss, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-prison",
   "metadata": {},
   "source": [
    "### Imputing missing values with IterativeImputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default estimator/regressor is Baysian Ridge\n",
    "ii_imputer = IterativeImputer(max_iter=10, random_state=11)\n",
    "\n",
    "df_ii = df_miss.copy()\n",
    "df_ii.iloc[:, :] = ii_imputer.fit_transform(df_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ii.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-contemporary",
   "metadata": {},
   "source": [
    "### Imputing missing values with other variants of IterativeImputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "rf_imputer = IterativeImputer(estimator=rf, random_state=17)\n",
    "\n",
    "df_rf = df_miss.copy()\n",
    "df_rf.iloc[:, :] = rf_imputer.fit_transform(df_rf)\n",
    "df_rf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-links",
   "metadata": {},
   "source": [
    "### Imputing missing values with KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "df_knn = df_miss.copy()\n",
    "df_knn.iloc[:, :] = knn_imputer.fit_transform(df_knn)\n",
    "df_knn.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-wayne",
   "metadata": {},
   "source": [
    "### Testing the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df_miss[\"sepal length (cm)\"].isna()) | (df_miss[\"petal width (cm)\"].isna())\n",
    "# df_miss[mask]\n",
    "df_miss = df_miss.dropna()\n",
    "datasets = [df, df_miss, df_ii, df_knn, df_rf]\n",
    "dfnames = [\"original\", \"drop missing\", \"iterative imputed\", \"knn imputed\", \"Random Forests imputed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C = 0.9)\n",
    "for i in range(len(datasets)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(datasets[i].iloc[:, 0:4], datasets[i][\"species\"], \\\n",
    "                                                        test_size=0.3, random_state=41)\n",
    "    logit.fit(X_train, y_train)\n",
    "    print(f\"Scores for the {dfnames[i]} dataset are\")\n",
    "    print(\"Training: {:6.2f}%\".format(100*logit.score(X_train, y_train)))\n",
    "    print(\"Test: {:6.2f}%\".format(100*logit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-bradford",
   "metadata": {},
   "source": [
    "### Extra steps to impute categorical feature (with strings as values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical values (strings) to numeric either with OrdinalEncoder or one_hot_encoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "feature_OE = OrdinalEncoder( )\n",
    "\n",
    "#pull out the feature to be imputed\n",
    "feature_impute = df[\"target_feature\"]\n",
    "\n",
    "#get all the observed categories of the feature\n",
    "feture_impute_observed = feature_impute[feature_impute.notnull( )] \n",
    "  \n",
    "#reshape feature_impute_notnull to a 2D array\n",
    "reshape_vals = var_impute_notnull.values.reshape(-1, 1)\n",
    "\n",
    "#convert levels of the categorical feature to numbers\n",
    "encoded_vals = feature_OE.fit_transform(reshape_vals)\n",
    "\n",
    "#put the transformed values back to the dataset\n",
    "data.loc[feature_impute.notnull( ), \"target_feature\"] = np.squeeze(encoded_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation, and round imputed values to integers since categories are represented by integers\n",
    "ii_imputer = IterativeImputer(max_iter=10, random_state=11)\n",
    "df.iloc[:, :] = np.round(ii_imputer.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse the transformation\n",
    "levels = df[\"target_feature\"].values.reshape(-1, 1)\n",
    "df[\"target_feature\"] = feature_OE.inverse_transform(levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-support",
   "metadata": {},
   "source": [
    "### Questions? <br> More specifics of the functions used in the demo can be found from sklearn:\n",
    "<img src=\"friends_minion.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-soccer",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. https://scikit-learn.org/stable/modules/impute.html#multivariate-feature-imputation\n",
    "2. https://learn.datacamp.com/courses/dealing-with-missing-data-in-python\n",
    "3. https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-airline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
